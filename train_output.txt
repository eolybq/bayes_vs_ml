0 = negative
1 = neutral
2 = positive
Started Logistic Model MCMC sampling
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [intercept, betas]

                             Step     Grad      Sampl…
  Progr…   Draws   Diverg…   size     evals     Speed    Elapsed   Remai…
 ─────────────────────────────────────────────────────────────────────────
  ━━━━━━   2000    0         0.032    1023      1.31     0:43:47   0:00:…
                                                s/draw
  ━━━━━━   2000    0         0.043    127       1.00     0:33:26   0:00:…
                                                s/draw
  ━━━━━━   2000    0         0.038    255       1.03     0:34:24   0:00:…
                                                s/draw
  ━━━━━━   2000    0         0.035    127       1.04     0:32:00   0:00:…
                                                draws…

Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2628 seconds.
Saving Logistic Model MCMC samples
Sampling: [obs]
Sampling ... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:01
Saving posterior train samples
Summary:
                  mean     sd  hdi_3%  ...  ess_bulk  ess_tail  r_hat
intercept[0]    -0.511  0.587  -1.630  ...    4222.0    3179.0    1.0
intercept[1]     1.219  0.586   0.116  ...    4231.0    2876.0    1.0
intercept[2]    -0.739  0.586  -1.846  ...    4268.0    2966.0    1.0
betas[0, 0]      0.126  0.686  -1.217  ...    6384.0    3721.0    1.0
betas[0, 1]     -0.428  0.649  -1.674  ...    5826.0    3346.0    1.0
...                ...    ...     ...  ...       ...       ...    ...
probs[11998, 1]  0.267  0.084   0.125  ...    4681.0    3337.0    1.0
probs[11998, 2]  0.688  0.089   0.528  ...    4936.0    3377.0    1.0
probs[11999, 0]  0.299  0.099   0.131  ...    4649.0    3487.0    1.0
probs[11999, 1]  0.172  0.071   0.051  ...    5393.0    3688.0    1.0
probs[11999, 2]  0.528  0.108   0.328  ...    4894.0    3557.0    1.0

[37503 rows x 9 columns]
Max R-hat: 1.0065860550529229
Min Ess: 3235.801428252865
Sampling: [obs]
Sampling ... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:12
Map: 100%|█████████████████| 10200/10200 [00:00<00:00, 25561.17 examples/s]
Map: 100%|███████████████████| 1800/1800 [00:00<00:00, 26320.41 examples/s]
-----fine-tuning FinBERT-----
  0%|                                             | 0/1914 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniconda/base/envs/d_science/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.
{'loss': 0.7451, 'grad_norm': 11.166641235351562, 'learning_rate': 1.478578892371996e-05, 'epoch': 0.78}
{'eval_loss': 0.5870906710624695, 'eval_accuracy': 0.7655555555555555, 'eval_f1': 0.7645501911618372, 'eval_runtime': 31.4486, 'eval_samples_per_second': 57.236, 'eval_steps_per_second': 3.593, 'epoch': 1.0}
 33%|███████████▋                       | 638/1914 [12:08<17:06,  1.24it/s/opt/homebrew/Caskroom/miniconda/base/envs/d_science/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.
{'loss': 0.4779, 'grad_norm': 8.78627872467041, 'learning_rate': 9.561128526645768e-06, 'epoch': 1.57}
{'eval_loss': 0.5992459058761597, 'eval_accuracy': 0.7727777777777778, 'eval_f1': 0.7711599286230307, 'eval_runtime': 39.7125, 'eval_samples_per_second': 45.326, 'eval_steps_per_second': 2.845, 'epoch': 2.0}
 67%|██████████████████████▋           | 1276/1914 [24:33<10:14,  1.04it/s/opt/homebrew/Caskroom/miniconda/base/envs/d_science/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.
{'loss': 0.3644, 'grad_norm': 19.432476043701172, 'learning_rate': 4.3364681295715785e-06, 'epoch': 2.35}
{'eval_loss': 0.6641101241111755, 'eval_accuracy': 0.7755555555555556, 'eval_f1': 0.7747100585177548, 'eval_runtime': 35.2258, 'eval_samples_per_second': 51.099, 'eval_steps_per_second': 3.208, 'epoch': 3.0}
{'train_runtime': 2228.0729, 'train_samples_per_second': 13.734, 'train_steps_per_second': 0.859, 'train_loss': 0.4705147658520482, 'epoch': 3.0}
100%|██████████████████████████████████| 1914/1914 [37:08<00:00,  1.16s/it]
-----Naive Bayes Evaluation-----
              precision    recall  f1-score   support

    negative       0.55      0.68      0.61       804
     neutral       0.64      0.52      0.58      1166
    positive       0.61      0.63      0.62      1030

    accuracy                           0.60      3000
   macro avg       0.60      0.61      0.60      3000
weighted avg       0.61      0.60      0.60      3000

Naive Bayes Roc Auc Score: 0.7915971366612237
Naive Bayes Log loss: 0.9666817059646071
-----Logistic Regression Evaluation-----
              precision    recall  f1-score   support

    negative       0.65      0.53      0.58       804
     neutral       0.63      0.68      0.66      1166
    positive       0.62      0.65      0.64      1030

    accuracy                           0.63      3000
   macro avg       0.63      0.62      0.62      3000
weighted avg       0.63      0.63      0.63      3000

Logistic Regression Roc Auc Score: 0.8138732493670799
Logistic Regression Log loss: 0.810375753521685
-----FinBERT Evaluation-----
              precision    recall  f1-score   support

    negative       0.71      0.89      0.79       804
     neutral       0.79      0.70      0.74      1166
    positive       0.80      0.74      0.77      1030

    accuracy                           0.77      3000
   macro avg       0.77      0.78      0.77      3000
weighted avg       0.77      0.77      0.76      3000

FinBERT Roc Auc Score: 0.9189986959792676
FinBERT Log loss: 0.5712936339720216
